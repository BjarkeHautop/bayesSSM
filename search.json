[{"path":"https://bjarkehautop.github.io/bayesSSM/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 bayesSSM authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"sir-model","dir":"Articles","previous_headings":"","what":"SIR model","title":"sir-model","text":"implement following SIR model. Consider closed population size NN (.e. births, deaths migration) three compartments: susceptible, infected recovered. assume initially every individual susceptible except mm infected individuals. assume indivudlas infectious period, contacts given member population occur according time-homogeneous Poisson process rate λ/n\\lambda/n, λ>0\\lambda > 0 nn number susceptible. susceptible individual contacted, become infected instantaneously subsequently follow infectious process. let distribution infection period, II exponential distributed: ∼Exp(γ)\\sim \\text{Exp}(\\gamma) γ>0\\gamma > 0. Let S(t)S(t) denote number susceptible individuals (t)(t) denote number infectious individuals time t≥0t \\geq 0. Note, assumptions {(S(t),(t)):t≥0} \\{(S(t), (t)) : t \\geq 0\\}  Markov process, since infection event exponential distributed (since time next event Poisson process exponential) removal event, thus memoryless. infection removal events following rates: Infection Event: transition (s,)→(s−1,+1)   (s,) \\(s-1, +1)    occurs rate λnsi,   \\frac{\\lambda}{n}\\, s\\, ,    s>0s > 0 >0i > 0. Removal Event: transition (s,)→(s,−1)   (s,) \\(s, -1)    occurs rate γi,   \\gamma\\, ,    >0i > 0.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"partial-observations-and-noisy-measurements","dir":"Articles","previous_headings":"SIR model","what":"Partial observations and noisy measurements","title":"sir-model","text":"Suppose observe initial state number infectious individuals, (t)(t), discrete times t=0,1,…,Tt = 0, 1, \\ldots, T. assume true number infectious individuals latent state observe noisy version state, either higher lower (often lower). model Poisson distribution: Yt∣(t)∼Pois((t)). Y_t \\mid (t) \\sim \\operatorname{Pois}((t)).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"sir-model","text":"simulate data SIR model following parameters: - t=0t=0 S(0)=90S(0) = 90, (0)=10I(0) = 10 R(0)=0R(0) = 0. - Infection rate λ=1.5\\lambda=1.5 removal rate γ=0.5\\gamma=0.5. - observe initial state t=0t=0 complete, noisy version infectious individuals times t=1,…,10t=1, \\ldots, 10 representing observations day. can simulate using fact two independent exponential distribution, event occurs rate sum rates. Now, generate data: plot :  interested performing Bayesian inference setup. define priors define priors λ,γ\\lambda, \\gamma ϕ\\phi λ∼half-N(1),γ∼half-N(2),1ϕ∼half-N(1),\\begin{align*}     \\lambda \\sim \\text{half-}N(1), \\\\     \\gamma \\sim \\text{half-}N(2), \\\\     \\frac{1}{\\sqrt{\\phi}} \\sim \\text{half-}N(1), \\end{align*} half-N()\\text{half-}N() denotes half-normal distribution mean 00 standard deviation aa. prior -dispersion parameter ϕ\\phi follows recommendation https://mc-stan.org/users/documentation/case-studies. define priors, since specify prior ϕ\\phi another scale need include Jacobian term likelihood. now define initial state, transition likelihood functions SIR model. Now can run PMMH algorithm estimate posterior distribution. vignette use small number iterations (1000) 2 chains (also modify tuning use 100 iterations burn-10). practice, much higher. get convergence warnings expected, posterior still centered around true value. can access chains plot densities: λ\\lambda:  γ\\gamma:","code":"# --- Simulation settings and true parameters --- n_total <- 500 # Total population size init_infected <- 70 # Initially infectious individuals init_state <- c(n_total - init_infected, init_infected) # (s, i) at time 0 t_max <- 10 # Total number of days to simulate true_lambda <- 0.5 # True infection parameter true_gamma <- 0.2 # True removal parameter  # --- Functions for simulating the epidemic ---  epidemic_step <- function(state, lambda, gamma, n_total) {   t <- 0   t_end <- 1   s <- state[1]   i <- state[2]   while (t < t_end && i > 0) {     rate_infection <- (lambda / n_total) * s * i     rate_removal <- gamma * i     rate_total <- rate_infection + rate_removal     if (rate_total <= 0) break     dt <- rexp(1, rate_total)     if (t + dt > t_end) break     t <- t + dt     # Decide which event occurs:     if (runif(1) < rate_infection / rate_total) {       # Infection event       s <- s - 1       i <- i + 1     } else {       # Removal event       i <- i - 1     }   }   c(s, i) }  simulate_epidemic <- function(     n_total, init_infected, lambda, gamma, t_max) {   states <- matrix(0, nrow = t_max, ncol = 2)   # initial state at t = 0   state <- c(n_total - init_infected, init_infected)   for (t in 1:t_max) {     state <- epidemic_step(state, lambda, gamma, n_total)     states[t, ] <- state   }   states } # Simulate an epidemic dataset true_states <- simulate_epidemic(   n_total, init_infected, true_lambda, true_gamma, t_max ) latent_i <- true_states[, 2]  observations <- rpois(length(latent_i), lambda = latent_i)  # Display simulated data: time, susceptible, latent infectious, observed counts print(data.frame(   time = 1:t_max, s = true_states[, 1], i = true_states[, 2], y = observations )) #>    time   s   i   y #> 1     1 391  88 103 #> 2     2 348 113 106 #> 3     3 307 132 114 #> 4     4 266 147 136 #> 5     5 221 164 155 #> 6     6 183 171 168 #> 7     7 155 159 154 #> 8     8 137 143 137 #> 9     9 118 139 147 #> 10   10 107 121 123 # Function to create a tidy dataset for ggplot prepare_data_for_plot <- function(states, observations, t_max) {   # Organize the data into a tidy format   data <- data.frame(     time = 1:t_max,     s = states[, 1],     i = states[, 2],     y = observations   )    # Convert to long format for ggplot   data_long <- data %>%     gather(key = \"state\", value = \"count\", -time)    data_long }  # Function to plot the epidemic data plot_epidemic_data <- function(data_long, t_max) {   ggplot(data_long, aes(x = time, y = count, color = state)) +     geom_line(linewidth = 1.2) +     scale_color_manual(values = c(\"s\" = \"blue\", \"i\" = \"red\", \"y\" = \"green\")) +     labs(       x = \"Time (Days)\", y = \"Count\",       title = \"Susceptible, Infected, and Observed Counts\"     ) +     theme_minimal() +     theme(legend.title = element_blank()) +     scale_x_continuous(breaks = 1:t_max) +     theme(       axis.title = element_text(size = 12),       plot.title = element_text(size = 14, hjust = 0.5)     ) }  # Prepare data for plotting data_long <- prepare_data_for_plot(true_states, observations, t_max)  # Plot the results plot_epidemic_data(data_long, t_max) # Define the log-prior for the parameters log_prior_lambda <- function(lambda) {   extraDistr::dhnorm(lambda, sigma = 1, log = TRUE) }  log_prior_gamma <- function(gamma) {   extraDistr::dhnorm(gamma, sigma = 2, log = TRUE) }  log_prior_phi <- function(phi) {   if (phi <= 0) {     return(-Inf)   } # Ensure phi is positive    # Jacobian: |d(1/sqrt(phi))/dphi| = 1/(2 * phi^(3/2))   log_jacobian <- -log(2) - 1.5 * log(phi)   extraDistr::dhnorm(1 / sqrt(phi), sigma = 1, log = TRUE) + log_jacobian }  log_priors <- list(   lambda = log_prior_lambda,   gamma = log_prior_gamma ) init_fn_epidemic <- function(num_particles) {   # Return a matrix with particles rows; each row is the initial state (s, i)   matrix(     rep(init_state, each = num_particles),     nrow = num_particles,     byrow = FALSE   ) }  transition_fn_epidemic <- function(particles, lambda, gamma, t) {   new_particles <- t(apply(particles, 1, function(state) {     s <- state[1]     i <- state[2]     if (i == 0) {       return(c(s, i))     }     epidemic_step(state, lambda, gamma, n_total)   }))   new_particles }  log_likelihood_fn_epidemic <- function(y, particles) {   # particles is expected to be a matrix with columns (s, i)   dpois(y, lambda = particles[, 2], log = TRUE) } result <- bayesSSM::pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   param_transform = list(lambda = \"log\", gamma = \"log\"),   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405, ) #> Running chain 1... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5744942 0.2023182 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0049477745 0.0008807493 #> gamma  0.0008807493 0.0001576646 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5228747 0.1919012 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0018259219 0.0005323758 #> gamma  0.0005323758 0.0001830201 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>     lambda 0.57 0.07   0.56 0.42  0.72 109 1.012 #>      gamma 0.21 0.02   0.21 0.17  0.24  70 1.020 #> Warning in bayesSSM::pmmh(y = observations, m = 1000, init_fn = #> init_fn_epidemic, : Some ESS values are below 400, indicating poor mixing. #> Consider running the chains for more iterations. #> Warning in bayesSSM::pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in. chains <- result$theta_chain ggplot(chains, aes(x = lambda, fill = factor(chain))) +   geom_density(alpha = 0.5) +   labs(     title = \"Density plot of lambda chains\",     x = \"Value\",     y = \"Density\",     fill = \"Chain\"   ) +   theme_minimal() ggplot(chains, aes(x = gamma, fill = factor(chain))) +   geom_density(alpha = 0.5) +   labs(     title = \"Density plot of gamma chains\",     x = \"Value\",     y = \"Density\",     fill = \"Chain\"   ) +   theme_minimal()"},{"path":"https://bjarkehautop.github.io/bayesSSM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bjarke Hautop. Author, maintainer, copyright holder.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hautop B (2025). bayesSSM: Bayesian Methods State Space Models. R package version 0.5.0.9003, https://github.com/BjarkeHautop/bayesSSM.","code":"@Manual{,   title = {bayesSSM: Bayesian Methods for State Space Models},   author = {Bjarke Hautop},   year = {2025},   note = {R package version 0.5.0.9003},   url = {https://github.com/BjarkeHautop/bayesSSM}, }"},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"bayesssm-","dir":"","previous_headings":"","what":"Bayesian Methods for State Space Models","title":"Bayesian Methods for State Space Models","text":"bayesSSM R package offering set tools performing Bayesian inference state-space models (SSMs). implements Particle Marginal Metropolis-Hastings (PMMH) main function pmmh Bayesian inference SSMs.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"why-bayesssm","dir":"","previous_headings":"","what":"Why bayesSSM?","title":"Bayesian Methods for State Space Models","text":"several alternative packages available performing Particle MCMC, bayesSSM designed simple easy use. alongside Master’s thesis Particle MCMC, since implementing everything scratch anyway. Everything written R, performance best.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Methods for State Space Models","text":"can install latest stable version bayesSSM CRAN : development version GitHub :","code":"install.packages(\"bayesSSM\") # install.packages(\"pak\") pak::pak(\"BjarkeHautop/bayesSSM\")"},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Methods for State Space Models","text":"Consider following SSM: X0∼N(0,1)Xt=ϕXt−1+sin(Xt−1)+σxVt,Vt∼N(0,1),t≥1Yt=Xt+σyWt,Wt∼N(0,1),t≥1 \\begin{aligned}         X_0 &\\sim N(0,1) \\\\         X_t&=\\phi X_{t-1}+\\sin(X_{t-1})+\\sigma_x V_t, \\quad V_t \\sim N(0,1), \\quad t\\geq 1 \\\\         Y_t&=X_t+\\sigma_y W_t, \\quad W_t \\sim N(0, 1), \\quad t\\geq 1 \\end{aligned} Let’s first simulate 20 data points model ϕ=0.8\\phi = 0.8, σx=1\\sigma_x = 1, σy=0.5\\sigma_y = 0.5. define priors model follows: ϕ∼Uniform(0,1),σx∼Exp(1),σy∼Exp(1). \\begin{aligned}         \\phi &\\sim \\text{Uniform}(0,1), \\\\         \\sigma_x &\\sim \\text{Exp}(1), \\\\         \\sigma_y &\\sim \\text{Exp}(1). \\end{aligned} can use pmmh perform Bayesian inference model. use pmmh need define functions SSM priors. functions init_fn, transition_fn functions simulates latent states. init_fn must contain argument num_particles initializing particles, transition_fn must contain argument particles, vector particles, can contain arguments model-specific parameters. function log_likelihood_fn function calculates log-likelihood observed data given latent state variables. must contain arguments y data particles. Time-dependency can implemented giving t argument transition_fn log_likelihood_fn. priors parameters must defined log-prior functions. Every parameter init_fn, transition_fn, log_likelihood_fn must corresponding log-prior function. Now can run PMMH algorithm using pmmh function. README use lower number samples smaller burn-period, also modify pilot chains use 200 samples. make example run faster. get convergence warnings expected due small number iterations.","code":"set.seed(1405) t_val <- 20 phi <- 0.8 sigma_x <- 1 sigma_y <- 0.5  init_state <- rnorm(1, mean = 0, sd = 1) x <- numeric(t_val) y <- numeric(t_val) x[1] <- phi * init_state + sin(init_state) +   rnorm(1, mean = 0, sd = sigma_x) y[1] <- x[1] + rnorm(1, mean = 0, sd = sigma_y) for (t in 2:t_val) {   x[t] <- phi * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma_x)   y[t] <- x[t] + rnorm(1, mean = 0, sd = sigma_y) } x <- c(init_state, x) init_fn <- function(num_particles) {   rnorm(num_particles, mean = 0, sd = 1) } transition_fn <- function(particles, phi, sigma_x) {   phi * particles + sin(particles) +     rnorm(length(particles), mean = 0, sd = sigma_x) } log_likelihood_fn <- function(y, particles, sigma_y) {  dnorm(y, mean = particles, sd = sigma_y, log = TRUE) } log_prior_phi <- function(phi) {   dunif(phi, min = 0, max = 1, log = TRUE) } log_prior_sigma_x <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_prior_sigma_y <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) }  log_priors <- list(   phi = log_prior_phi,   sigma_x = log_prior_sigma_x,   sigma_y = log_prior_sigma_y ) library(bayesSSM)  result <- pmmh(   y = y,   m = 500, # number of MCMC samples   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.4, sigma_x = 0.4, sigma_y = 0.4),     c(phi = 0.8, sigma_x = 0.8, sigma_y = 0.8)   ),   burn_in = 50,   num_chains = 2,   seed = 1405,   tune_control = default_tune_control(pilot_m = 200, pilot_burn_in = 10) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 298 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 242 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>        phi 0.78 0.08   0.79 0.61  0.96 102 1.007 #>    sigma_x 0.50 0.41   0.36 0.02  1.18   8 1.388 #>    sigma_y 0.88 0.42   1.04 0.09  1.37   7 1.393 #> Warning in pmmh(y = y, m = 500, init_fn = init_fn, transition_fn = #> transition_fn, : Some ESS values are below 400, indicating poor mixing. #> Consider running the chains for more iterations. #> Warning in pmmh(y = y, m = 500, init_fn = init_fn, transition_fn = transition_fn, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"state-space-models","dir":"","previous_headings":"","what":"State-space Models","title":"Bayesian Methods for State Space Models","text":"state-space model (SSM) structure given following diagram, omitted potential time-dependency transition observation densities simplicity.  core function, pmmh, implements Particle Marginal Metropolis-Hastings, algorithm first generates set NN particles approximate likelihood uses approximation acceptance probability. implementation automatically tunes number particles proposal distribution parameters.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate effective sample size (ESS) of MCMC chains. — ess","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Estimate effective sample size (ESS) MCMC chains.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"","code":"ess(chains)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"chains matrix (iterations x chains) data.frame 'chain' column parameter columns.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"estimated effective sample size (ess) given matrix, named vector ESS values given data frame.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Uses formula ESS proposed Vehtari et al. (2021).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Vehtari et al. (2021). Rank-normalization, folding, localization: improved R-hat assessing convergence MCMC. Available : https://doi.org/10.1214/20-BA1221","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"","code":"# With a matrix: chains <- matrix(rnorm(3000), nrow = 1000, ncol = 3) ess(chains) #> [1] 2970.728  # With a data frame: chains_df <- data.frame(   chain = rep(1:3, each = 1000),   param1 = rnorm(3000),   param2 = rnorm(3000) ) ess(chains_df) #>   param1   param2  #> 2857.517 3000.000"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Tuning Control Parameters — default_tune_control","title":"Create Tuning Control Parameters — default_tune_control","text":"function creates list tuning parameters used pmmh function. tuning choices inspired Pitt et al. [2012] Dahlin Schön [2019].","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Tuning Control Parameters — default_tune_control","text":"","code":"default_tune_control(   pilot_proposal_sd = 0.5,   pilot_n = 100,   pilot_m = 2000,   pilot_target_var = 1,   pilot_burn_in = 500,   pilot_reps = 100,   pilot_algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   pilot_resample_fn = c(\"stratified\", \"systematic\", \"multinomial\") )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Tuning Control Parameters — default_tune_control","text":"pilot_proposal_sd Standard deviation pilot proposals. Default 0.5. pilot_n Number pilot particles particle filter. Default 100. pilot_m Number iterations MCMC. Default 2000. pilot_target_var target variance posterior log-likelihood evaluated estimated posterior mean. Default 1. pilot_burn_in Number burn-iterations MCMC. Default 500. pilot_reps Number times particle filter run. Default 100. pilot_algorithm algorithm used pilot particle filter. Default \"SISAR\". pilot_resample_fn resampling function used pilot particle filter. Default \"stratified\".","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Tuning Control Parameters — default_tune_control","text":"list tuning control parameters.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create Tuning Control Parameters — default_tune_control","text":"M. K. Pitt, R. d. S. Silva, P. Giordani, R. Kohn. properties Markov chain Monte Carlo simulation methods based particle filter. Journal Econometrics, 171(2):134–151, 2012. doi: https://doi.org/10.1016/j.jeconom.2012.06.004 J. Dahlin T. B. Schön. Getting started particle Metropolis-Hastings inference nonlinear dynamical models. Journal Statistical Software, 88(2):1–41, 2019. doi: 10.18637/jss.v088.c02","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to back-transform parameters — .back_transform_params","title":"Internal function to back-transform parameters — .back_transform_params","text":"Internal function back-transform parameters","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to back-transform parameters — .back_transform_params","text":"","code":".back_transform_params(theta_trans, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to back-transform parameters — .back_transform_params","text":"theta_trans transformed parameter vector transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to back-transform parameters — .back_transform_params","text":"original parameter vector","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to validate input of user-defined functions and priors — .check_params_match","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"Helper function validate input user-defined functions priors","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"","code":".check_params_match(   init_fn,   transition_fn,   log_likelihood_fn,   pilot_init_params,   log_priors )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"init_fn function initialize state-space model. transition_fn function defines state transition state-space model. log_likelihood_fn function calculates log-likelihood state-space model given latent states. pilot_init_params vector initial parameter values. log_priors list functions computing log-prior parameter.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"Internal function compute Jacobian transformation","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"","code":".compute_log_jacobian(theta, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"theta parameter vector (original scale) transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"log-Jacobian transformation","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-pilot_run.html","id":null,"dir":"Reference","previous_headings":"","what":"Pilot Run for Particle Filter Tuning — .pilot_run","title":"Pilot Run for Particle Filter Tuning — .pilot_run","text":"internal function repeatedly evaluates particle filter order estimate variance log-likelihoods compute recommended target number particles Particle Marginal Metropolis Hastings (PMMH) algorithm.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-pilot_run.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pilot Run for Particle Filter Tuning — .pilot_run","text":"","code":".pilot_run(   y,   pilot_n,   pilot_reps,   init_fn,   transition_fn,   log_likelihood_fn,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   ... )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-pilot_run.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pilot Run for Particle Filter Tuning — .pilot_run","text":"y numeric vector matrix observations. row represents observation time step. pilot_n integer specifying initial number particles use. pilot_reps integer specifying number repetitions pilot run. init_fn function initializes particle states. take current particles first argument return vector matrix initial particle states. transition_fn function describing state transition model. take current particles current time step arguments return propagated particles. log_likelihood_fn function computes log likelihoods particles. accept observation, current particles, current time step arguments return numeric vector log likelihood values. obs_times numeric vector indicating time points observations y available. Must length number rows y. specified, assumed observations available consecutive time steps, .e., obs_times = 1:nrow(y). algorithm character string specifying particle filtering algorithm use. Must one \"SISAR\", \"SISR\", \"SIS\". Defaults \"SISAR\". resample_fn character string specifying resampling method. Must one \"stratified\", \"systematic\", \"multinomial\". Defaults \"stratified\". ... Additional arguments passed `init_fn`, `transition_fn`, `log_likelihood_fn`.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-pilot_run.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pilot Run for Particle Filter Tuning — .pilot_run","text":"list containing: variance_estimate estimated variance log-likelihoods   pilot run. target_N number particles used PMMH algorithm. pilot_loglikes numeric vector log-likelihood values computed   run.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-pilot_run.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pilot Run for Particle Filter Tuning — .pilot_run","text":"function performs pilot_reps evaluations particle filter using provided parameter vector theta. estimates variance log-likelihoods scales initial particle number variance. final number particles taken ceiling scaled value minimum 50 maximum 1000.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-resample_multinomial.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal Resampling Functions — .resample_multinomial","title":"Internal Resampling Functions — .resample_multinomial","text":"Helper functions resampling particles particle filter. functions implement multinomial, stratified, systematic resampling.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-resample_multinomial.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal Resampling Functions — .resample_multinomial","text":"","code":".resample_multinomial(particles, weights)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-run_pilot_chain.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","title":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","text":"Run Pilot Chain Posterior Estimation","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-run_pilot_chain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","text":"","code":".run_pilot_chain(   y,   pilot_m,   pilot_n,   pilot_reps,   init_fn,   transition_fn,   log_likelihood_fn,   log_priors,   proposal_sd,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   param_transform = NULL,   pilot_init_params = NULL,   verbose = FALSE,   ... )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-run_pilot_chain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","text":"y numeric vector observations. pilot_m integer specifying number iterations pilot chain. pilot_n integer specifying number particles particle filter. pilot_reps integer specifying number repetitions pilot run. init_fn function initialize state space model. transition_fn function defines state transition dynamics state space model. log_likelihood_fn function computes log-likelihood observations given model parameters. log_priors list functions representing log-priors model parameter. proposal_sd numeric vector specifying standard deviations random walk proposal distribution parameter. obs_times numeric vector observation times. provided, function assumes observations available every time step. algorithm character string specifying particle filter algorithm use. One \"SISAR\", \"SISR\", \"SIS\". Default \"SISAR\". resample_fn character string specifying resampling method use. One \"stratified\", \"systematic\", \"multinomial\". Default \"stratified\". param_transform character vector specifying parameter transformations proposing parameters using random walk. Currently supports \"log\" log-transformation \"identity\" transformation. Default `NULL`, correspond transformation (\"identity). pilot_init_params numeric vector initial parameter values. `NULL`, default vector ones. Default `NULL`. ... Additional arguments passed particle filter function.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-run_pilot_chain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","text":"list containing: pilot_theta_mean numeric vector posterior mean parameters. pilot_theta_cov matrix posterior covariance (variance one parameter). target_N estimated target number particles PMMH algorithm. pilot_theta_chain matrix containing chain parameter values throughout pilot run. pilot_loglike_chain vector containing log-likelihood values associated iteration pilot chain.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-run_pilot_chain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Run Pilot Chain for Posterior Estimation — .run_pilot_chain","text":"function runs pilot chain estimate posterior mean covariance model parameters using particle filter. chain run `pilot_m` iterations, iteration proposing new parameters evaluating likelihood prior. chain used estimate posterior mean covariance, used tune number particles Particle Marginal Metropolis Hastings (PMMH) algorithm.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to transform parameters — .transform_params","title":"Internal function to transform parameters — .transform_params","text":"Internal function transform parameters","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to transform parameters — .transform_params","text":"","code":".transform_params(theta, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to transform parameters — .transform_params","text":"theta parameter vector transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to transform parameters — .transform_params","text":"transformed parameter vector","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Particle Filter — particle_filter","title":"Particle Filter — particle_filter","text":"function implements bootstrap particle filter estimating hidden states state space model using sequential Monte Carlo methods. Three filtering variants supported: SIS: Sequential Importance Sampling (without resampling). SISR: Sequential Importance Sampling resampling   every time step. SISAR: SIS adaptive resampling based Effective   Sample Size (ESS). Resampling triggered ESS falls   given threshold (default particles / 2). recommended use either SISR SISAR avoid weight degeneracy.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Particle Filter — particle_filter","text":"","code":"particle_filter(   y,   num_particles,   init_fn,   transition_fn,   log_likelihood_fn,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   threshold = NULL,   return_particles = TRUE,   ... )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Particle Filter — particle_filter","text":"y numeric vector matrix observations. row represents observation time step. observations equally spaced, use obs_times argument specify time points observations available. num_particles positive integer specifying number particles. init_fn function initializes particle states. take `num_particles` argument initializing particles return vector matrix initial particle states. can include model-specific parameters named arguments. transition_fn function describing state transition model. take `particles` argument return propagated particles. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_likelihood_fn function computes log-likelihoods particles. take `y` argument observations, current particles, return numeric vector log-likelihood values. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. obs_times numeric vector indicating time points observations y available. Must length number rows y. specified, assumed observations available consecutive time steps, .e., obs_times = 1:nrow(y). algorithm character string specifying particle filtering algorithm use. Must one \"SISAR\", \"SISR\", \"SIS\". Defaults \"SISAR\". resample_fn character string specifying resampling method. Must one \"stratified\", \"systematic\", \"multinomial\". Defaults \"stratified\". threshold numeric value specifying ESS threshold triggering resampling \"SISAR\" algorithm. provided, defaults num_particles / 2. return_particles logical value indicating whether return full particle history. Defaults TRUE. ... Additional arguments passed init_fn, transition_fn, log_likelihood_fn. .e., parameter values functions requires .","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Particle Filter — particle_filter","text":"list containing: state_est numeric vector estimated states     time, computed weighted average particles. ess numeric vector Effective Sample Size (ESS)     time step. loglike accumulated log-likelihood observations given     model. loglike_history numeric vector log-likelihood     time step. algorithm character string indicating filtering algorithm     used. particles_history (Optional) matrix particle states     time, dimension (num_obs + 1) x num_particles. Returned     return_particles TRUE. weights_history (Optional) matrix particle weights time,     dimension (num_obs + 1) x num_particles. Returned     return_particles TRUE.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Particle Filter — particle_filter","text":"particle filter sequential Monte Carlo method approximates posterior distribution state state space model. three supported algorithms differ approach resampling: SIS: Particles propagated weighted without    resampling, may lead weight degeneracy time. SISR: Resampling performed every time step combat   weight degeneracy. SISAR: Resampling performed adaptively; particles   resampled Effective Sample Size (ESS) falls   specified threshold (defaulting particles / 2). Effective Sample Size (ESS) context particle filters defined $$ESS = \\left(\\sum_{=1}^{\\text{n}} w_i^2\\right)^{-1},$$ \\(n\\) number particles \\(w_i\\) normalized weights particles. default resampling method stratified resampling, Douc et al., 2005 showed always gives lower variance compared multinomial resampling.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Particle Filter — particle_filter","text":"Douc, R., Cappé, O., & Moulines, E. (2005). Comparison Resampling Schemes Particle Filtering. Accessible : https://arxiv.org/abs/cs/0507025","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Particle Filter — particle_filter","text":"","code":"init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles) particles + rnorm(length(particles)) log_likelihood_fn <- function(y, particles) {   dnorm(y, mean = particles, sd = 1, log = TRUE) }  y <- cumsum(rnorm(50)) # dummy data num_particles <- 100  # Run the particle filter using default settings. result <- particle_filter(   y = y,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, y))) points(y, col = \"red\", pch = 20)   # With parameters init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles, mu) {   particles + rnorm(length(particles), mean = mu) } log_likelihood_fn <- function(y, particles, sigma) {   dnorm(y, mean = particles, sd = sigma, log = TRUE) }  y <- cumsum(rnorm(50)) # dummy data num_particles <- 100  # Run the particle filter using default settings. result <- particle_filter(   y = y,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   mu = 1,   sigma = 1 ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, y))) points(y, col = \"red\", pch = 20)   # With observations gaps init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles, mu) {   particles + rnorm(length(particles), mean = mu) } log_likelihood_fn <- function(y, particles, sigma) {   dnorm(y, mean = particles, sd = sigma, log = TRUE) }  # Generate data using DGP simulate_ssm <- function(num_steps, mu, sigma) {   x <- numeric(num_steps)   y <- numeric(num_steps)   x[1] <- rnorm(1, mean = 0, sd = sigma)   y[1] <- rnorm(1, mean = x[1], sd = sigma)   for (t in 2:num_steps) {     x[t] <- mu * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma)     y[t] <- x[t] + rnorm(1, mean = 0, sd = sigma)   }   y }  data <- simulate_ssm(10, mu = 1, sigma = 1) # Suppose we have data for t=1,2,3,5,6,7,8,9,10 (i.e., missing at t=4)  obs_times <- c(1, 2, 3, 5, 6, 7, 8, 9, 10) data_obs <- data[obs_times]  num_particles <- 100 # Run the particle filter # Specify observation times in the particle filter using obs_times result <- particle_filter(   y = data_obs,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   obs_times = obs_times,   mu = 1,   sigma = 1, ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, data))) points(data_obs, col = \"red\", pch = 20)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":null,"dir":"Reference","previous_headings":"","what":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"function implements Particle Marginal Metropolis-Hastings (PMMH) algorithm perform Bayesian inference state-space models. first runs pilot chain tune proposal distribution number particles particle filter, runs main PMMH chain.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"","code":"pmmh(   y,   m,   init_fn,   transition_fn,   log_likelihood_fn,   log_priors,   pilot_init_params,   burn_in,   num_chains = 4,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   param_transform = NULL,   tune_control = default_tune_control(),   verbose = FALSE,   return_latent_state_est = FALSE,   seed = NULL,   num_cores = 1 )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"y numeric vector matrix observations. row represents observation time step. m integer specifying total number MCMC iterations. init_fn function initializes particle states. take `num_particles` argument initializing particles return vector matrix initial particle states. can include model-specific parameters named arguments. transition_fn function describing state transition model. take `particles` argument return propagated particles. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_likelihood_fn function computes log-likelihoods particles. take `y` argument observations, current particles, return numeric vector log-likelihood values. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_priors list functions computing log-prior parameter. pilot_init_params list initial parameter values. list length num_chains element named vector initial parameter values. burn_in integer indicating number initial MCMC iterations discard burn-. num_chains integer specifying number PMMH chains run. obs_times numeric vector indicating time points observations y available. Must length number rows y. specified, assumed observations available consecutive time steps, .e., obs_times = 1:nrow(y). algorithm character string specifying particle filtering algorithm use. Must one \"SISAR\", \"SISR\", \"SIS\". Defaults \"SISAR\". resample_fn character string specifying resampling method. Must one \"stratified\", \"systematic\", \"multinomial\". Defaults \"stratified\". param_transform optional character vector specifies transformation applied parameter proposing. proposal made using multivariate normal distribution transformed scale. Parameters mapped back original scale evaluation. Currently supports \"log\", \"logit\", \"identity\". NULL, \"identity\" transformation used parameters. tune_control list pilot tuning controls (e.g., pilot\\_m, pilot\\_reps). See default_tune_control. verbose logical value indicating whether print information pilot_run tuning. Defaults FALSE. return_latent_state_est logical value indicating whether return latent state estimates time step. Defaults FALSE. seed optional integer set seed reproducibility. num_cores integer specifying number cores use parallel processing. Defaults 1. chain assigned core, number cores exceed number chains (num_chains). progress information given user limited using one core.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"list containing: theta_chain dataframe post burn-parameter samples. latent_state_chain return_latent_state_est   TRUE, list matrices containing latent state estimates   time step. diagnostics Diagnostics containing ESS Rhat   parameter (see ess rhat   documentation).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"PMMH algorithm essentially Metropolis Hastings algorithm instead using exact likelihood instead uses estimated using likelihood using particle filter (see also particle_filter). Values proposed using multivariate normal distribution transformed space. proposal covariance estimated using pilot chain.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"Andrieu et al. (2010). Particle Markov chain Monte Carlo methods. Journal Royal Statistical Society: Series B (Statistical Methodology), 72(3):269–342. doi: 10.1111/j.1467-9868.2009.00736.x","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"","code":"init_fn <- function(num_particles) {   rnorm(num_particles, mean = 0, sd = 1) } transition_fn <- function(particles, phi, sigma_x) {   phi * particles + sin(particles) +     rnorm(length(particles), mean = 0, sd = sigma_x) } log_likelihood_fn <- function(y, particles, sigma_y) {   dnorm(y, mean = cos(particles), sd = sigma_y, log = TRUE) } log_prior_phi <- function(phi) {   dnorm(phi, mean = 0, sd = 1, log = TRUE) } log_prior_sigma_x <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_prior_sigma_y <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_priors <- list(   phi = log_prior_phi,   sigma_x = log_prior_sigma_x,   sigma_y = log_prior_sigma_y ) # Generate data t_val <- 10 x <- numeric(t_val) y <- numeric(t_val) phi <- 0.8 sigma_x <- 1 sigma_y <- 0.5  init_state <- rnorm(1, mean = 0, sd = 1) x[1] <- phi * init_state + sin(init_state) + rnorm(1, mean = 0, sd = sigma_x) y[1] <- x[1] + rnorm(1, mean = 0, sd = sigma_y) for (t in 2:t_val) {   x[t] <- phi * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma_x)   y[t] <- cos(x[t]) + rnorm(1, mean = 0, sd = sigma_y) } x <- c(init_state, x)  # Should use much higher MCMC iterations in practice (m) pmmh_result <- pmmh(   y = y,   m = 1000,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.8, sigma_x = 1, sigma_y = 0.5),     c(phi = 1, sigma_x = 0.5, sigma_y = 1)   ),   burn_in = 100,   num_chains = 2,   param_transform = list(     phi = \"identity\",     sigma_x = \"log\",     sigma_y = \"log\"   ),   tune_control = default_tune_control(pilot_m = 500, pilot_burn_in = 100) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median  2.5% 97.5% ESS  Rhat #>        phi 0.54 1.03   0.66 -1.68  2.34  25 1.022 #>    sigma_x 1.55 1.23   1.29  0.08  4.75  64 1.044 #>    sigma_y 0.64 0.24   0.61  0.30  1.21  91 1.016 #> Warning: Some ESS values are below 400, indicating poor mixing. Consider running the chains for more iterations. #> Warning:  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in. # Convergence warning is expected with such low MCMC iterations.  # Suppose we have data for t=1,2,3,5,6,7,8,9,10 (i.e., missing at t=4)  obs_times <- c(1, 2, 3, 5, 6, 7, 8, 9, 10) y <- y[obs_times]  # Specify observation times in the pmmh using obs_times pmmh_result <- pmmh(   y = y,   m = 1000,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.8, sigma_x = 1, sigma_y = 0.5),     c(phi = 1, sigma_x = 0.5, sigma_y = 1)   ),   burn_in = 100,   num_chains = 2,   obs_times = obs_times,   param_transform = list(     phi = \"identity\",     sigma_x = \"log\",     sigma_y = \"log\"   ),   tune_control = default_tune_control(pilot_m = 500, pilot_burn_in = 100) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median  2.5% 97.5% ESS  Rhat #>        phi 0.14 1.21   0.37 -2.24  2.23  36 1.088 #>    sigma_x 1.68 1.21   1.49  0.07  4.59  68 1.046 #>    sigma_y 0.67 0.24   0.62  0.33  1.28  83 1.017 #> Warning: Some ESS values are below 400, indicating poor mixing. Consider running the chains for more iterations. #> Warning:  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for PMMH output — print.pmmh_output","title":"Print method for PMMH output — print.pmmh_output","text":"Displays concise summary parameter estimates PMMH output object, including means, standard deviations, medians, 95% credible intervals, effective sample sizes (ESS), Rhat. provides quick overview posterior distribution convergence diagnostics.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for PMMH output — print.pmmh_output","text":"","code":"# S3 method for class 'pmmh_output' print(x, ...)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for PMMH output — print.pmmh_output","text":"x object class `pmmh_output`. ... Additional arguments.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for PMMH output — print.pmmh_output","text":"object `x` invisibly.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for PMMH output — print.pmmh_output","text":"","code":"# Create dummy chains for two parameters across two chains chain1 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 1) chain2 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 2) dummy_output <- list(   theta_chain = rbind(chain1, chain2),   diagnostics = list(     ess = c(param1 = 200, param2 = 190),     rhat = c(param1 = 1.01, param2 = 1.00)   ) ) class(dummy_output) <- \"pmmh_output\" print(dummy_output) #> PMMH Results Summary: #>  Parameter Mean   SD Median  2.5% 97.5% ESS Rhat #>     param1 0.02 1.06   0.04 -1.98  2.00 200 1.01 #>     param2 0.12 1.00   0.10 -1.88  2.04 190 1.00"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute split Rhat statistic — rhat","title":"Compute split Rhat statistic — rhat","text":"Compute split Rhat statistic","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute split Rhat statistic — rhat","text":"","code":"rhat(chains)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute split Rhat statistic — rhat","text":"chains matrix (iterations x chains) data.frame 'chain' column parameter columns.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute split Rhat statistic — rhat","text":"Rhat value (matrix input) named vector Rhat values.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute split Rhat statistic — rhat","text":"Uses formula split-Rhat proposed Gelman et al. (2013).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute split Rhat statistic — rhat","text":"Gelman et al. (2013). Bayesian Data Analysis, 3rd Edition.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute split Rhat statistic — rhat","text":"","code":"# Example with matrix chains <- matrix(rnorm(3000), nrow = 1000, ncol = 3) rhat(chains) #> [1] 1.00017 #' # Example with data frame chains_df <- data.frame(   chain = rep(1:3, each = 1000),   param1 = rnorm(3000),   param2 = rnorm(3000) ) rhat(chains_df) #>   param1   param2  #> 1.000000 1.000399"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for PMMH output — summary.pmmh_output","title":"Summary method for PMMH output — summary.pmmh_output","text":"function returns summary statistics PMMH output objects, including means, standard deviations, medians, credible intervals, diagnostics.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for PMMH output — summary.pmmh_output","text":"","code":"# S3 method for class 'pmmh_output' summary(object, ...)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for PMMH output — summary.pmmh_output","text":"object object class `pmmh_output`. ... Additional arguments.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for PMMH output — summary.pmmh_output","text":"data frame containing summary statistics parameter.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for PMMH output — summary.pmmh_output","text":"","code":"# Create dummy chains for two parameters across two chains chain1 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 1) chain2 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 2) dummy_output <- list(   theta_chain = rbind(chain1, chain2),   diagnostics = list(     ess = c(param1 = 200, param2 = 190),     rhat = c(param1 = 1.01, param2 = 1.00)   ) ) class(dummy_output) <- \"pmmh_output\" summary(dummy_output) #>               mean        sd     median      2.5%    97.5% ESS Rhat #> param1 -0.09052223 0.9867457  0.0139562 -2.124148 2.005799 200 1.01 #> param2 -0.12282298 1.0834494 -0.1747597 -2.195476 2.122307 190 1.00"},{"path":[]},{"path":"https://bjarkehautop.github.io/bayesSSM/news/index.html","id":"bayesssm-050","dir":"Changelog","previous_headings":"","what":"bayesSSM 0.5.0","title":"bayesSSM 0.5.0","text":"CRAN release: 2025-05-21 particles argument init_fn, passed particle_filter pmmh, deprecated. Please use num_particles instead. warning issued particles used. Added support time dependency functions. can now use t transition_fn likelihood_fn passing particle_filter pmmh. allows time-varying transition likelihood functions. Fixed bug particle_filter likelihood calculation causing shifted constant. Improved robustness pmmh encountering low log-likelihood values. Added scaling proposal covariance using \"logit\" pmmh. Improved documentation: updated package description, clarified text README vignette, added unit tests.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/news/index.html","id":"bayesssm-047","dir":"Changelog","previous_headings":"","what":"bayesSSM 0.4.7","title":"bayesSSM 0.4.7","text":"CRAN release: 2025-04-23 Initial CRAN submission.","code":""}]
