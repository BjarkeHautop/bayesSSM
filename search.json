[{"path":"https://bjarkehautop.github.io/bayesSSM/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 bayesSSM authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"theoretical-background","dir":"Articles","previous_headings":"","what":"Theoretical Background","title":"Detailed Overview of bayesSSM Package","text":"bayesSSM package designed facilitate Bayesian inference state space models (SSMs). package defines state space model diagram (potential time dependency shown simplicity): wish perform Bayesian inference setting, target distribution p(x0:T,θ∣y1:T)∝π(θ)p(x0:T∣θ)p(y1:T∣x0:T,θ), p(x_{0:T}, \\theta \\mid y_{1:T}) \\propto \\pi(\\theta) \\, p(x_{0:T} \\mid \\theta)  \\, p(y_{1:T} \\mid x_{0:T}, \\theta),  π(θ)\\pi(\\theta) prior distribution parameters θ\\theta, p(x0:T∣θ)p(x_{0:T} \\mid \\theta) distribution latent states, p(y1:T∣x0:T,θ)p(y_{1:T} \\mid x_{0:T}, \\theta) distribution observations given latent states parameters. naive MCMC approaches sample (x0:T,θ)(x_{0:T}, \\theta) jointly, often infeasible due high dimensionality latent states. Another approach marginalize latent states sample parameters θ\\theta, also often infeasible due integral intractable. Instead, use Particle Markov chain Monte Carlo (PMMH) approach, samples latent states parameters two steps: Sample latent states x0:Tx_{0:T} given parameters θ\\theta observations y1:Ty_{1:T} using particle filter. Sample parameters θ\\theta given latent states x0:Tx_{0:T} observations y1:Ty_{1:T} using Metropolis-Hastings step. key idea , since particle filter provides unbiased estimate likelihood, PMMH algorithm still targets correct posterior distribution stationary distribution. avoid weight degeneracy particle filter, recommended use resampling, focus particles higher weights (high probability).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"example-fitting-a-state-space-model","dir":"Articles","previous_headings":"","what":"Example: Fitting a State Space Model","title":"Detailed Overview of bayesSSM Package","text":"show fit stochastic SIR model using bayesSSM package ( see also sir-model article bayesSSM package). First, generate synthetic data model.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"simulate-data","dir":"Articles","previous_headings":"Example: Fitting a State Space Model","what":"Simulate data","title":"Detailed Overview of bayesSSM Package","text":"simulate data SIR model following parameters: t=0t=0 S(0)=90S(0) = 90, (0)=10I(0) = 10 R(0)=0R(0) = 0. Infection rate λ=0.5\\lambda=0.5 removal rate γ=0.2\\gamma=0.2. observe initial state t=0t=0 complete, noisy version infectious individuals times t=1,…,10t=1, \\ldots, 10 representing observations day. can simulate using fact two independent exponential distribution, event occurs rate sum rates. Now, generate data: plot :","code":"# --- Simulation settings and true parameters --- n_total <- 500 # Total population size init_infected <- 70 # Initially infectious individuals init_state <- c(n_total - init_infected, init_infected) # (s, i) at time 0 t_max <- 10 # Total number of days to simulate true_lambda <- 0.5 # True infection parameter true_gamma <- 0.2 # True removal parameter  # --- Functions for simulating the epidemic ---  epidemic_step <- function(state, lambda, gamma, n_total) {   t <- 0   t_end <- 1   s <- state[1]   i <- state[2]   while (t < t_end && i > 0) {     rate_infection <- (lambda / n_total) * s * i     rate_removal <- gamma * i     rate_total <- rate_infection + rate_removal     if (rate_total <= 0) break     dt <- rexp(1, rate_total)     if (t + dt > t_end) break     t <- t + dt     # Decide which event occurs:     if (runif(1) < rate_infection / rate_total) {       # Infection event       s <- s - 1       i <- i + 1     } else {       # Removal event       i <- i - 1     }   }   c(s, i) }  simulate_epidemic <- function(     n_total, init_infected, lambda, gamma, t_max) {   states <- matrix(0, nrow = t_max, ncol = 2)   # initial state at t = 0   state <- c(n_total - init_infected, init_infected)   for (t in 1:t_max) {     state <- epidemic_step(state, lambda, gamma, n_total)     states[t, ] <- state   }   states } # Simulate an epidemic dataset true_states <- simulate_epidemic(   n_total, init_infected, true_lambda, true_gamma, t_max ) latent_i <- true_states[, 2]  observations <- rpois(length(latent_i), lambda = latent_i)  # Display simulated data: time, susceptible, latent infectious, observed counts print(data.frame(   time = 1:t_max, s = true_states[, 1], i = true_states[, 2], y = observations )) #>    time   s   i   y #> 1     1 391  88 103 #> 2     2 348 113 106 #> 3     3 307 132 114 #> 4     4 266 147 136 #> 5     5 221 164 155 #> 6     6 183 171 168 #> 7     7 155 159 154 #> 8     8 137 143 137 #> 9     9 118 139 147 #> 10   10 107 121 123 # Function to create a tidy dataset for ggplot prepare_data_for_plot <- function(states, observations, t_max) {   # Organize the data into a tidy format   data <- data.frame(     time = 1:t_max,     s = states[, 1],     i = states[, 2],     y = observations   )    # Convert to long format for ggplot   data_long <- data %>%     gather(key = \"state\", value = \"count\", -time)    data_long }  # Function to plot the epidemic data plot_epidemic_data <- function(data_long, t_max) {   ggplot(data_long, aes(x = time, y = count, color = state)) +     geom_line(linewidth = 1.2) +     scale_color_manual(values = c(\"s\" = \"blue\", \"i\" = \"red\", \"y\" = \"green\")) +     labs(       x = \"Time (Days)\", y = \"Count\",       title = \"Susceptible, Infected, and Observed Counts\"     ) +     theme_minimal() +     theme(legend.title = element_blank()) +     scale_x_continuous(breaks = 1:t_max) +     theme(       axis.title = element_text(size = 12),       plot.title = element_text(size = 14, hjust = 0.5)     ) }  # Prepare data for plotting data_long <- prepare_data_for_plot(true_states, observations, t_max)  # Plot the results plot_epidemic_data(data_long, t_max)"},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"fitting-the-model","dir":"Articles","previous_headings":"Example: Fitting a State Space Model","what":"Fitting the model","title":"Detailed Overview of bayesSSM Package","text":"define initialization, transition, log-likelihood functions SIR model. Note, define variables used functions inside functions, can used parallel processing (see also tips tricks section ). initialization function init_fn must take argument num_particles return matrix particles, row corresponds particle’s initial state (susceptible infected individuals). example use deterministic initialization fixed number susceptible infected individuals. transition function transition_fn must take argument particles return matrix particles, row corresponds particle’s state next time step. log-likelihood function log_likelihood_fn must take arguments y particles, return vector log-likelihood values particle. time dependency can implemented giving t argument transition_fn log_likelihood_fn. example, time dependency, use t argument. priors λ,γ\\lambda, \\gamma λ∼half-N(1),γ∼half-N(2).\\begin{align*}     \\lambda \\sim \\text{half-}N(1), \\\\     \\gamma \\sim \\text{half-}N(2). \\\\ \\end{align*} Now can run PMMH algorithm estimate posterior distribution (modify tuning draw 1000 samples speed ).","code":"init_fn_epidemic <- function(num_particles) {   # Return a matrix with num_particles rows   # each row is the initial state (s, i)   n_total <- 500   init_infected <- 70   init_state <- c(S = n_total - init_infected, I = init_infected)   matrix(     rep(init_state, each = num_particles),     nrow = num_particles,     byrow = FALSE   ) }  transition_fn_epidemic <- function(particles, lambda, gamma, t) {    n_total <- 500    epidemic_step <- function(state, lambda, gamma, n_total) {     t <- 0     t_end <- 1     s <- state[1]     i <- state[2]     while (t < t_end && i > 0) {       rate_infection <- (lambda / n_total) * s * i       rate_removal <- gamma * i       rate_total <- rate_infection + rate_removal       if (rate_total <= 0) break       dt <- rexp(1, rate_total)       if (t + dt > t_end) break       t <- t + dt       # Decide which event occurs:       if (runif(1) < rate_infection / rate_total) {         # Infection event         s <- s - 1         i <- i + 1       } else {         # Removal event         i <- i - 1       }     }     c(s, i)   }    new_particles <- t(apply(particles, 1, function(state) {     s <- state[1]     i <- state[2]     if (i == 0) {       return(c(s, i))     }     epidemic_step(state, lambda, gamma, n_total)   }))   new_particles }  log_likelihood_fn_epidemic <- function(y, particles, t) {   # particles is expected to be a matrix with columns (s, i)   dpois(y, lambda = particles[, 2], log = TRUE) } log_prior_lambda <- function(lambda) {   extraDistr::dhnorm(lambda, sigma = 1, log = TRUE) }  log_prior_gamma <- function(gamma) {   extraDistr::dhnorm(gamma, sigma = 2, log = TRUE) }  log_priors <- list(   lambda = log_prior_lambda,   gamma = log_prior_gamma ) result <- pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405 ) #> Running chain 1... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.4884500 0.1862124 #> Pilot chain posterior covariance: #>             lambda        gamma #> lambda 0.004595206 0.0011484070 #> gamma  0.001148407 0.0003359767 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.6228020 0.2469006 #> Pilot chain posterior covariance: #>               lambda         gamma #> lambda  0.0045776235 -0.0002264161 #> gamma  -0.0002264161  0.0024275942 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>     lambda 0.54 0.08   0.54 0.41  0.69  60 1.036 #>      gamma 0.20 0.02   0.21 0.15  0.24  70 1.039 #> Warning in pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, : Some #> ESS values are below 400, indicating poor mixing. Consider running the chains #> for more iterations. #> Warning in pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":[]},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"using-several-cores","dir":"Articles","previous_headings":"Tips and Tricks","what":"Using Several Cores","title":"Detailed Overview of bayesSSM Package","text":"use several cores (number chains), can set num_cores argument pmmh function. code run PMMH algorithm using 2 cores, useful speeding sampling process, especially larger datasets complex models. Note, global variables must explicitly defined within functions exported worker processes. .e, n_total, init_infected, init_state variables must defined within init_fn_epidemic, transition_fn_epidemic, log_likelihood_fn_epidemic functions, shown .","code":"result <- pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405,   num_cores = 2 )"},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"sampling-on-an-unconstrained-space","dir":"Articles","previous_headings":"Tips and Tricks","what":"Sampling on an Unconstrained Space","title":"Detailed Overview of bayesSSM Package","text":"allow efficient sampling, can use param_transform argument propose new parameters unconstrained space, leading efficient sampling. Since λ\\lambda γ\\gamma take values (0,∞)(0, \\infty), can use log transformation.","code":"result <- pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405,   param_transform = list(lambda = \"log\", gamma = \"log\") )"},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"using-rcpp","dir":"Articles","previous_headings":"Tips and Tricks","what":"Using Rcpp","title":"Detailed Overview of bayesSSM Package","text":"transition log-likelihood functions computationally expensive, can speed sampling process using Rcpp implement functions C++. example transition function SIR model. C++ implementation much faster R implementation, speed PMMH sampling process significantly, especially larger datasets complex models. Now, can use C++ function pmmh function passing transition_fn argument.","code":"cppFunction(\" NumericMatrix transition_fn_epidemic_cpp(     NumericMatrix particles,      double lambda,      double gamma ) {    int n_particles = particles.nrow();   int n_total = 500;   double t_end = 1.0; // Time step for the transition   NumericMatrix new_particles(n_particles, 2);      for (int p = 0; p < n_particles; p++) {     int s = particles(p, 0);     int i = particles(p, 1);          if (i == 0) {       new_particles(p, 0) = s;       new_particles(p, 1) = i;       continue;     }          double t = 0.0;          while (t < t_end && i > 0) {       double rate_infection = (lambda / n_total) * s * i;       double rate_removal = gamma * i;       double rate_total = rate_infection + rate_removal;              if (rate_total <= 0.0) {         break;       }              double dt = R::rexp(1.0 / rate_total);       if (t + dt > t_end) {         break;       }              t += dt;              if (R::runif(0.0, 1.0) < (rate_infection / rate_total)) {         // Infection event         s -= 1;         i += 1;       } else {         // Removal event         i -= 1;       }     }          new_particles(p, 0) = s;     new_particles(p, 1) = i;   }      return new_particles; } \") result_cpp <- pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic_cpp,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405,   param_transform = list(lambda = \"log\", gamma = \"log\") ) #> Running chain 1... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5744942 0.2023182 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0049477745 0.0008807493 #> gamma  0.0008807493 0.0001576646 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5228747 0.1919012 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0018259219 0.0005323758 #> gamma  0.0005323758 0.0001830201 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>     lambda 0.57 0.07   0.56 0.42  0.72 109 1.012 #>      gamma 0.21 0.02   0.21 0.17  0.24  70 1.020 #> Warning in pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, : Some #> ESS values are below 400, indicating poor mixing. Consider running the chains #> for more iterations. #> Warning in pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"observation-times","dir":"Articles","previous_headings":"Tips and Tricks","what":"Observation Times","title":"Detailed Overview of bayesSSM Package","text":"bayesSSM package allows specify observation times observations. useful observations equally spaced time. can specify observation times using obs_times argument pmmh function. observation times vector length observations, contain time points observations made. example use obs_times argument, assume observations made times 1, 2, 3 6.","code":"obs_times <- c(1, 2, 3, 6) new_observations <- observations[obs_times] result_obs_times <- pmmh(   y = new_observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405,   param_transform = list(lambda = \"log\", gamma = \"log\"),   obs_times = obs_times )"},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/detailed-overview.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Detailed Overview of bayesSSM Package","text":"article, provided detailed overview bayesSSM package use Bayesian inference state space models. shown define model, simulate data, fit model using PMMH algorithm. also provided tips tricks using package effectively, including use several cores, sample unconstrained space, use Rcpp faster sampling.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"sir-model","dir":"Articles","previous_headings":"","what":"SIR model","title":"Stochastic SIR Model","text":"implement following SIR model. Consider closed population size NN (.e. births, deaths migration) three compartments: susceptible, infected recovered. assume initially every individual susceptible except mm infected individuals. assume indivudlas infectious period, contacts given member population occur according time-homogeneous Poisson process rate λ/n\\lambda/n, λ>0\\lambda > 0 nn number susceptible. susceptible individual contacted, become infected instantaneously subsequently follow infectious process. let distribution infection period, II exponential distributed: ∼Exp(γ)\\sim \\text{Exp}(\\gamma) γ>0\\gamma > 0. Let S(t)S(t) denote number susceptible individuals (t)(t) denote number infectious individuals time t≥0t \\geq 0. Note, assumptions {(S(t),(t)):t≥0} \\{(S(t), (t)) : t \\geq 0\\}  Markov process, since infection event exponential distributed (since time next event Poisson process exponential) removal event, thus memoryless. infection removal events following rates: Infection Event: transition (s,)→(s−1,+1)   (s,) \\(s-1, +1)    occurs rate λnsi,   \\frac{\\lambda}{n}\\, s\\, ,    s>0s > 0 >0i > 0. Removal Event: transition (s,)→(s,−1)   (s,) \\(s, -1)    occurs rate γi,   \\gamma\\, ,    >0i > 0.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"partial-observations-and-noisy-measurements","dir":"Articles","previous_headings":"SIR model","what":"Partial observations and noisy measurements","title":"Stochastic SIR Model","text":"Suppose observe initial state number infectious individuals, (t)(t), discrete times t=0,1,…,Tt = 0, 1, \\ldots, T. assume true number infectious individuals latent state observe noisy version state, either higher lower (often lower). model Poisson distribution: Yt∣(t)∼Pois((t)). Y_t \\mid (t) \\sim \\operatorname{Pois}((t)).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/articles/sir-model.html","id":"simulate-data","dir":"Articles","previous_headings":"","what":"Simulate data","title":"Stochastic SIR Model","text":"simulate data SIR model following parameters: - t=0t=0 S(0)=90S(0) = 90, (0)=10I(0) = 10 R(0)=0R(0) = 0. - Infection rate λ=1.5\\lambda=1.5 removal rate γ=0.5\\gamma=0.5. - observe initial state t=0t=0 complete, noisy version infectious individuals times t=1,…,10t=1, \\ldots, 10 representing observations day. can simulate using fact two independent exponential distribution, event occurs rate sum rates. Now, generate data: plot :  interested performing Bayesian inference setup. define priors define priors λ,γ\\lambda, \\gamma ϕ\\phi λ∼half-N(1),γ∼half-N(2),1ϕ∼half-N(1),\\begin{align*}     \\lambda \\sim \\text{half-}N(1), \\\\     \\gamma \\sim \\text{half-}N(2), \\\\     \\frac{1}{\\sqrt{\\phi}} \\sim \\text{half-}N(1), \\end{align*} half-N()\\text{half-}N() denotes half-normal distribution mean 00 standard deviation aa. prior -dispersion parameter ϕ\\phi follows recommendation https://mc-stan.org/users/documentation/case-studies. define priors, since specify prior ϕ\\phi another scale need include Jacobian term likelihood. now define initial state, transition likelihood functions SIR model. Now can run PMMH algorithm estimate posterior distribution. vignette use small number iterations (1000) 2 chains (also modify tuning use 100 iterations burn-10). practice, much higher. get convergence warnings expected, posterior still centered around true value. can access chains plot densities: λ\\lambda:  γ\\gamma:","code":"# --- Simulation settings and true parameters --- n_total <- 500 # Total population size init_infected <- 70 # Initially infectious individuals init_state <- c(n_total - init_infected, init_infected) # (s, i) at time 0 t_max <- 10 # Total number of days to simulate true_lambda <- 0.5 # True infection parameter true_gamma <- 0.2 # True removal parameter  # --- Functions for simulating the epidemic ---  epidemic_step <- function(state, lambda, gamma, n_total) {   t <- 0   t_end <- 1   s <- state[1]   i <- state[2]   while (t < t_end && i > 0) {     rate_infection <- (lambda / n_total) * s * i     rate_removal <- gamma * i     rate_total <- rate_infection + rate_removal     if (rate_total <= 0) break     dt <- rexp(1, rate_total)     if (t + dt > t_end) break     t <- t + dt     # Decide which event occurs:     if (runif(1) < rate_infection / rate_total) {       # Infection event       s <- s - 1       i <- i + 1     } else {       # Removal event       i <- i - 1     }   }   c(s, i) }  simulate_epidemic <- function(     n_total, init_infected, lambda, gamma, t_max) {   states <- matrix(0, nrow = t_max, ncol = 2)   # initial state at t = 0   state <- c(n_total - init_infected, init_infected)   for (t in 1:t_max) {     state <- epidemic_step(state, lambda, gamma, n_total)     states[t, ] <- state   }   states } # Simulate an epidemic dataset true_states <- simulate_epidemic(   n_total, init_infected, true_lambda, true_gamma, t_max ) latent_i <- true_states[, 2]  observations <- rpois(length(latent_i), lambda = latent_i)  # Display simulated data: time, susceptible, latent infectious, observed counts print(data.frame(   time = 1:t_max, s = true_states[, 1], i = true_states[, 2], y = observations )) #>    time   s   i   y #> 1     1 391  88 103 #> 2     2 348 113 106 #> 3     3 307 132 114 #> 4     4 266 147 136 #> 5     5 221 164 155 #> 6     6 183 171 168 #> 7     7 155 159 154 #> 8     8 137 143 137 #> 9     9 118 139 147 #> 10   10 107 121 123 # Function to create a tidy dataset for ggplot prepare_data_for_plot <- function(states, observations, t_max) {   # Organize the data into a tidy format   data <- data.frame(     time = 1:t_max,     s = states[, 1],     i = states[, 2],     y = observations   )    # Convert to long format for ggplot   data_long <- data %>%     gather(key = \"state\", value = \"count\", -time)    data_long }  # Function to plot the epidemic data plot_epidemic_data <- function(data_long, t_max) {   ggplot(data_long, aes(x = time, y = count, color = state)) +     geom_line(linewidth = 1.2) +     scale_color_manual(values = c(\"s\" = \"blue\", \"i\" = \"red\", \"y\" = \"green\")) +     labs(       x = \"Time (Days)\", y = \"Count\",       title = \"Susceptible, Infected, and Observed Counts\"     ) +     theme_minimal() +     theme(legend.title = element_blank()) +     scale_x_continuous(breaks = 1:t_max) +     theme(       axis.title = element_text(size = 12),       plot.title = element_text(size = 14, hjust = 0.5)     ) }  # Prepare data for plotting data_long <- prepare_data_for_plot(true_states, observations, t_max)  # Plot the results plot_epidemic_data(data_long, t_max) # Define the log-prior for the parameters log_prior_lambda <- function(lambda) {   extraDistr::dhnorm(lambda, sigma = 1, log = TRUE) }  log_prior_gamma <- function(gamma) {   extraDistr::dhnorm(gamma, sigma = 2, log = TRUE) }  log_prior_phi <- function(phi) {   if (phi <= 0) {     return(-Inf)   } # Ensure phi is positive    # Jacobian: |d(1/sqrt(phi))/dphi| = 1/(2 * phi^(3/2))   log_jacobian <- -log(2) - 1.5 * log(phi)   extraDistr::dhnorm(1 / sqrt(phi), sigma = 1, log = TRUE) + log_jacobian }  log_priors <- list(   lambda = log_prior_lambda,   gamma = log_prior_gamma ) init_fn_epidemic <- function(num_particles) {   # Return a matrix with particles rows; each row is the initial state (s, i)   matrix(     rep(init_state, each = num_particles),     nrow = num_particles,     byrow = FALSE   ) }  transition_fn_epidemic <- function(particles, lambda, gamma, t) {   new_particles <- t(apply(particles, 1, function(state) {     s <- state[1]     i <- state[2]     if (i == 0) {       return(c(s, i))     }     epidemic_step(state, lambda, gamma, n_total)   }))   new_particles }  log_likelihood_fn_epidemic <- function(y, particles) {   # particles is expected to be a matrix with columns (s, i)   dpois(y, lambda = particles[, 2], log = TRUE) } result <- bayesSSM::pmmh(   y = observations,   m = 1000,   init_fn = init_fn_epidemic,   transition_fn = transition_fn_epidemic,   log_likelihood_fn = log_likelihood_fn_epidemic,   log_priors = log_priors,   pilot_init_params = list(     c(lambda = 0.5, gamma = 0.5),     c(lambda = 1, gamma = 1)   ),   burn_in = 200,   num_chains = 2,   param_transform = list(lambda = \"log\", gamma = \"log\"),   tune_control = default_tune_control(pilot_m = 100, pilot_burn_in = 10),   verbose = TRUE,   seed = 1405, ) #> Running chain 1... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5744942 0.2023182 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0049477745 0.0008807493 #> gamma  0.0008807493 0.0001576646 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Pilot chain posterior mean: #>    lambda     gamma  #> 0.5228747 0.1919012 #> Pilot chain posterior covariance (on transformed space): #>              lambda        gamma #> lambda 0.0018259219 0.0005323758 #> gamma  0.0005323758 0.0001830201 #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>     lambda 0.57 0.07   0.56 0.42  0.72 109 1.012 #>      gamma 0.21 0.02   0.21 0.17  0.24  70 1.020 #> Warning in bayesSSM::pmmh(y = observations, m = 1000, init_fn = #> init_fn_epidemic, : Some ESS values are below 400, indicating poor mixing. #> Consider running the chains for more iterations. #> Warning in bayesSSM::pmmh(y = observations, m = 1000, init_fn = init_fn_epidemic, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in. chains <- result$theta_chain ggplot(chains, aes(x = lambda, fill = factor(chain))) +   geom_density(alpha = 0.5) +   labs(     title = \"Density plot of lambda chains\",     x = \"Value\",     y = \"Density\",     fill = \"Chain\"   ) +   theme_minimal() ggplot(chains, aes(x = gamma, fill = factor(chain))) +   geom_density(alpha = 0.5) +   labs(     title = \"Density plot of gamma chains\",     x = \"Value\",     y = \"Density\",     fill = \"Chain\"   ) +   theme_minimal()"},{"path":"https://bjarkehautop.github.io/bayesSSM/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Bjarke Hautop. Author, maintainer, copyright holder.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Hautop B (2025). bayesSSM: Bayesian Methods State Space Models. R package version 0.5.0.9014, https://github.com/BjarkeHautop/bayesSSM.","code":"@Manual{,   title = {bayesSSM: Bayesian Methods for State Space Models},   author = {Bjarke Hautop},   year = {2025},   note = {R package version 0.5.0.9014},   url = {https://github.com/BjarkeHautop/bayesSSM}, }"},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"bayesssm-","dir":"","previous_headings":"","what":"Bayesian Methods for State Space Models","title":"Bayesian Methods for State Space Models","text":"bayesSSM R package offering set tools performing Bayesian inference state-space models (SSMs). implements Particle Marginal Metropolis-Hastings (PMMH) main function pmmh Bayesian inference SSMs.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"why-bayesssm","dir":"","previous_headings":"","what":"Why bayesSSM?","title":"Bayesian Methods for State Space Models","text":"several alternative packages available performing Particle MCMC, bayesSSM designed simple easy use. alongside Master’s thesis Particle MCMC, since implementing everything scratch anyway.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian Methods for State Space Models","text":"can install latest stable version bayesSSM CRAN : development version GitHub :","code":"install.packages(\"bayesSSM\") # install.packages(\"pak\") pak::pak(\"BjarkeHautop/bayesSSM\")"},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Bayesian Methods for State Space Models","text":"Consider following SSM: SSM equations Let’s first simulate 20 data points model ϕ=0.8\\phi = 0.8, σx=1\\sigma_x = 1, σy=0.5\\sigma_y = 0.5. define priors model follows: priors can use pmmh perform Bayesian inference model. use pmmh need define functions SSM priors. functions init_fn, transition_fn functions simulates latent states. init_fn must contain argument num_particles initializing particles, transition_fn must contain argument particles, vector particles, can contain arguments model-specific parameters. function log_likelihood_fn function calculates log-likelihood observed data given latent state variables. must contain arguments y data particles. Time-dependency can implemented giving t argument transition_fn log_likelihood_fn. priors parameters must defined log-prior functions. Every parameter init_fn, transition_fn, log_likelihood_fn must corresponding log-prior function. Now can run PMMH algorithm using pmmh function. README use lower number samples smaller burn-period, also modify pilot chains use 200 samples. make example run faster. get convergence warnings expected due small number iterations.","code":"set.seed(1405) t_val <- 20 phi <- 0.8 sigma_x <- 1 sigma_y <- 0.5  init_state <- rnorm(1, mean = 0, sd = 1) x <- numeric(t_val) y <- numeric(t_val) x[1] <- phi * init_state + sin(init_state) +   rnorm(1, mean = 0, sd = sigma_x) y[1] <- x[1] + rnorm(1, mean = 0, sd = sigma_y) for (t in 2:t_val) {   x[t] <- phi * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma_x)   y[t] <- x[t] + rnorm(1, mean = 0, sd = sigma_y) } x <- c(init_state, x) init_fn <- function(num_particles) {   rnorm(num_particles, mean = 0, sd = 1) } transition_fn <- function(particles, phi, sigma_x) {   phi * particles + sin(particles) +     rnorm(length(particles), mean = 0, sd = sigma_x) } log_likelihood_fn <- function(y, particles, sigma_y) {  dnorm(y, mean = particles, sd = sigma_y, log = TRUE) } log_prior_phi <- function(phi) {   dunif(phi, min = 0, max = 1, log = TRUE) } log_prior_sigma_x <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_prior_sigma_y <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) }  log_priors <- list(   phi = log_prior_phi,   sigma_x = log_prior_sigma_x,   sigma_y = log_prior_sigma_y ) library(bayesSSM)  result <- pmmh(   y = y,   m = 500, # number of MCMC samples   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.4, sigma_x = 0.4, sigma_y = 0.4),     c(phi = 0.8, sigma_x = 0.8, sigma_y = 0.8)   ),   burn_in = 50,   num_chains = 2,   seed = 1405,   tune_control = default_tune_control(pilot_m = 200, pilot_burn_in = 10) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median 2.5% 97.5% ESS  Rhat #>        phi 0.80 0.10   0.82 0.60  0.97  10 1.228 #>    sigma_x 0.58 0.50   0.46 0.00  1.71   2 1.376 #>    sigma_y 0.97 0.35   1.05 0.13  1.46   5 1.272 #> Warning in pmmh(y = y, m = 500, init_fn = init_fn, transition_fn = #> transition_fn, : Some ESS values are below 400, indicating poor mixing. #> Consider running the chains for more iterations. #> Warning in pmmh(y = y, m = 500, init_fn = init_fn, transition_fn = transition_fn, :  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":"https://bjarkehautop.github.io/bayesSSM/index.html","id":"state-space-models","dir":"","previous_headings":"","what":"State-space Models","title":"Bayesian Methods for State Space Models","text":"state-space model (SSM) structure given following diagram, omitted potential time-dependency transition observation densities simplicity.  core function, pmmh, implements Particle Marginal Metropolis-Hastings, algorithm first generates set NN particles approximate intractable marginal likelihood p(y1:T∣θ)p(y_{1:T} \\mid \\theta) uses approximation acceptance probability. implementation automatically tunes number particles proposal distribution parameters.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate effective sample size (ESS) of MCMC chains. — ess","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Estimate effective sample size (ESS) MCMC chains.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"","code":"ess(chains)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"chains matrix (iterations x chains) data.frame 'chain' column parameter columns.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"estimated effective sample size (ess) given matrix, named vector ESS values given data frame.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Uses formula ESS proposed Vehtari et al. (2021).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"Vehtari et al. (2021). Rank-normalization, folding, localization: improved R-hat assessing convergence MCMC. Available : https://doi.org/10.1214/20-BA1221","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/ESS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimate effective sample size (ESS) of MCMC chains. — ess","text":"","code":"# With a matrix: chains <- matrix(rnorm(3000), nrow = 1000, ncol = 3) ess(chains) #> [1] 2972.748  # With a data frame: chains_df <- data.frame(   chain = rep(1:3, each = 1000),   param1 = rnorm(3000),   param2 = rnorm(3000) ) ess(chains_df) #>   param1   param2  #> 2823.003 3000.000"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":null,"dir":"Reference","previous_headings":"","what":"Create Tuning Control Parameters — default_tune_control","title":"Create Tuning Control Parameters — default_tune_control","text":"function creates list tuning parameters used pmmh function. tuning choices inspired Pitt et al. [2012] Dahlin Schön [2019].","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create Tuning Control Parameters — default_tune_control","text":"","code":"default_tune_control(   pilot_proposal_sd = 0.5,   pilot_n = 100,   pilot_m = 2000,   pilot_target_var = 1,   pilot_burn_in = 500,   pilot_reps = 100,   pilot_algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   pilot_resample_fn = c(\"stratified\", \"systematic\", \"multinomial\") )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create Tuning Control Parameters — default_tune_control","text":"pilot_proposal_sd Standard deviation pilot proposals. Default 0.5. pilot_n Number pilot particles particle filter. Default 100. pilot_m Number iterations MCMC. Default 2000. pilot_target_var target variance posterior log-likelihood evaluated estimated posterior mean. Default 1. pilot_burn_in Number burn-iterations MCMC. Default 500. pilot_reps Number times particle filter run. Default 100. pilot_algorithm algorithm used pilot particle filter. Default \"SISAR\". pilot_resample_fn resampling function used pilot particle filter. Default \"stratified\".","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create Tuning Control Parameters — default_tune_control","text":"list tuning control parameters.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/default_tune_control.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Create Tuning Control Parameters — default_tune_control","text":"M. K. Pitt, R. d. S. Silva, P. Giordani, R. Kohn. properties Markov chain Monte Carlo simulation methods based particle filter. Journal Econometrics, 171(2):134–151, 2012. doi: https://doi.org/10.1016/j.jeconom.2012.06.004 J. Dahlin T. B. Schön. Getting started particle Metropolis-Hastings inference nonlinear dynamical models. Journal Statistical Software, 88(2):1–41, 2019. doi: 10.18637/jss.v088.c02","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to back-transform parameters — .back_transform_params","title":"Internal function to back-transform parameters — .back_transform_params","text":"Internal function back-transform parameters","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to back-transform parameters — .back_transform_params","text":"","code":".back_transform_params(theta_trans, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to back-transform parameters — .back_transform_params","text":"theta_trans transformed parameter vector transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-back_transform_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to back-transform parameters — .back_transform_params","text":"original parameter vector","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to validate input of user-defined functions and priors — .check_params_match","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"Helper function validate input user-defined functions priors","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"","code":".check_params_match(   init_fn,   transition_fn,   log_likelihood_fn,   pilot_init_params,   log_priors )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-check_params_match.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to validate input of user-defined functions and priors — .check_params_match","text":"init_fn function initialize state-space model. transition_fn function defines state transition state-space model. log_likelihood_fn function calculates log-likelihood state-space model given latent states. pilot_init_params vector initial parameter values. log_priors list functions computing log-prior parameter.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"Internal function compute Jacobian transformation","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"","code":".compute_log_jacobian(theta, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"theta parameter vector (original scale) transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-compute_log_jacobian.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to compute the Jacobian of the transformation — .compute_log_jacobian","text":"log-Jacobian transformation","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal function to transform parameters — .transform_params","title":"Internal function to transform parameters — .transform_params","text":"Internal function transform parameters","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal function to transform parameters — .transform_params","text":"","code":".transform_params(theta, transform)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal function to transform parameters — .transform_params","text":"theta parameter vector transform transformation type parameter","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/dot-transform_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal function to transform parameters — .transform_params","text":"transformed parameter vector","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":null,"dir":"Reference","previous_headings":"","what":"Particle Filter — particle_filter","title":"Particle Filter — particle_filter","text":"function implements bootstrap particle filter estimating hidden states state space model using sequential Monte Carlo methods. Three filtering variants supported: SIS: Sequential Importance Sampling (without resampling). SISR: Sequential Importance Sampling resampling   every time step. SISAR: SIS adaptive resampling based Effective   Sample Size (ESS). Resampling triggered ESS falls   given threshold (default particles / 2). recommended use either SISR SISAR avoid weight degeneracy.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Particle Filter — particle_filter","text":"","code":"particle_filter(   y,   num_particles,   init_fn,   transition_fn,   log_likelihood_fn,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   threshold = NULL,   return_particles = TRUE,   ... )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Particle Filter — particle_filter","text":"y numeric vector matrix observations. row represents observation time step. observations equally spaced, use obs_times argument specify time points observations available. num_particles positive integer specifying number particles. init_fn function initializes particle states. take `num_particles` argument initializing particles return vector matrix initial particle states. can include model-specific parameters named arguments. transition_fn function describing state transition model. take `particles` argument return propagated particles. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_likelihood_fn function computes log-likelihoods particles. take `y` argument observations, current particles, return numeric vector log-likelihood values. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. obs_times numeric vector indicating time points observations y available. Must length number rows y. specified, assumed observations available consecutive time steps, .e., obs_times = 1:nrow(y). algorithm character string specifying particle filtering algorithm use. Must one \"SISAR\", \"SISR\", \"SIS\". Defaults \"SISAR\". resample_fn character string specifying resampling method. Must one \"stratified\", \"systematic\", \"multinomial\". Defaults \"stratified\". threshold numeric value specifying ESS threshold triggering resampling \"SISAR\" algorithm. provided, defaults num_particles / 2. return_particles logical value indicating whether return full particle history. Defaults TRUE. ... Additional arguments passed init_fn, transition_fn, log_likelihood_fn. .e., parameter values functions requires .","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Particle Filter — particle_filter","text":"list containing: state_est numeric vector estimated states     time, computed weighted average particles. ess numeric vector Effective Sample Size (ESS)     time step. loglike accumulated log-likelihood observations given     model. loglike_history numeric vector log-likelihood     time step. algorithm character string indicating filtering algorithm     used. particles_history (Optional) matrix particle states     time, dimension (num_obs + 1) x num_particles. Returned     return_particles TRUE. weights_history (Optional) matrix particle weights time,     dimension (num_obs + 1) x num_particles. Returned     return_particles TRUE.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Particle Filter — particle_filter","text":"particle filter sequential Monte Carlo method approximates posterior distribution state state space model. three supported algorithms differ approach resampling: SIS: Particles propagated weighted without    resampling, may lead weight degeneracy time. SISR: Resampling performed every time step combat   weight degeneracy. SISAR: Resampling performed adaptively; particles   resampled Effective Sample Size (ESS) falls   specified threshold (defaulting particles / 2). Effective Sample Size (ESS) context particle filters defined $$ESS = \\left(\\sum_{=1}^{\\text{n}} w_i^2\\right)^{-1},$$ \\(n\\) number particles \\(w_i\\) normalized weights particles. default resampling method stratified resampling, Douc et al., 2005 showed always gives lower variance compared multinomial resampling.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Particle Filter — particle_filter","text":"Douc, R., Cappé, O., & Moulines, E. (2005). Comparison Resampling Schemes Particle Filtering. Accessible : https://arxiv.org/abs/cs/0507025","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/particle_filter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Particle Filter — particle_filter","text":"","code":"init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles) particles + rnorm(length(particles)) log_likelihood_fn <- function(y, particles) {   dnorm(y, mean = particles, sd = 1, log = TRUE) }  y <- cumsum(rnorm(50)) # dummy data num_particles <- 100  # Run the particle filter using default settings. result <- particle_filter(   y = y,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, y))) points(y, col = \"red\", pch = 20)   # With parameters init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles, mu) {   particles + rnorm(length(particles), mean = mu) } log_likelihood_fn <- function(y, particles, sigma) {   dnorm(y, mean = particles, sd = sigma, log = TRUE) }  y <- cumsum(rnorm(50)) # dummy data num_particles <- 100  # Run the particle filter using default settings. result <- particle_filter(   y = y,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   mu = 1,   sigma = 1 ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, y))) points(y, col = \"red\", pch = 20)   # With observations gaps init_fn <- function(num_particles) rnorm(num_particles, 0, 1) transition_fn <- function(particles, mu) {   particles + rnorm(length(particles), mean = mu) } log_likelihood_fn <- function(y, particles, sigma) {   dnorm(y, mean = particles, sd = sigma, log = TRUE) }  # Generate data using DGP simulate_ssm <- function(num_steps, mu, sigma) {   x <- numeric(num_steps)   y <- numeric(num_steps)   x[1] <- rnorm(1, mean = 0, sd = sigma)   y[1] <- rnorm(1, mean = x[1], sd = sigma)   for (t in 2:num_steps) {     x[t] <- mu * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma)     y[t] <- x[t] + rnorm(1, mean = 0, sd = sigma)   }   y }  data <- simulate_ssm(10, mu = 1, sigma = 1) # Suppose we have data for t=1,2,3,5,6,7,8,9,10 (i.e., missing at t=4)  obs_times <- c(1, 2, 3, 5, 6, 7, 8, 9, 10) data_obs <- data[obs_times]  num_particles <- 100 # Run the particle filter # Specify observation times in the particle filter using obs_times result <- particle_filter(   y = data_obs,   num_particles = num_particles,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   obs_times = obs_times,   mu = 1,   sigma = 1, ) plot(result$state_est, type = \"l\", col = \"blue\", main = \"State Estimates\",   ylim = range(c(result$state_est, data))) points(data_obs, col = \"red\", pch = 20)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":null,"dir":"Reference","previous_headings":"","what":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"function implements Particle Marginal Metropolis-Hastings (PMMH) algorithm perform Bayesian inference state-space models. first runs pilot chain tune proposal distribution number particles particle filter, runs main PMMH chain.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"","code":"pmmh(   y,   m,   init_fn,   transition_fn,   log_likelihood_fn,   log_priors,   pilot_init_params,   burn_in,   num_chains = 4,   obs_times = NULL,   algorithm = c(\"SISAR\", \"SISR\", \"SIS\"),   resample_fn = c(\"stratified\", \"systematic\", \"multinomial\"),   param_transform = NULL,   tune_control = default_tune_control(),   verbose = FALSE,   return_latent_state_est = FALSE,   seed = NULL,   num_cores = 1 )"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"y numeric vector matrix observations. row represents observation time step. observations equally spaced, use obs_times argument specify time points observations available. m integer specifying total number MCMC iterations. init_fn function initializes particle states. take `num_particles` argument initializing particles return vector matrix initial particle states. can include model-specific parameters named arguments. transition_fn function describing state transition model. take `particles` argument return propagated particles. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_likelihood_fn function computes log-likelihoods particles. take `y` argument observations, current particles, return numeric vector log-likelihood values. function can optionally depend time including time step argument `t`. can include model-specific parameters named arguments. log_priors list functions computing log-prior parameter. pilot_init_params list initial parameter values. list length num_chains element named vector initial parameter values. burn_in integer indicating number initial MCMC iterations discard burn-. num_chains integer specifying number PMMH chains run. obs_times numeric vector indicating time points observations y available. Must length number rows y. specified, assumed observations available consecutive time steps, .e., obs_times = 1:nrow(y). algorithm character string specifying particle filtering algorithm use. Must one \"SISAR\", \"SISR\", \"SIS\". Defaults \"SISAR\". resample_fn character string specifying resampling method. Must one \"stratified\", \"systematic\", \"multinomial\". Defaults \"stratified\". param_transform optional character vector specifies transformation applied parameter proposing. proposal made using multivariate normal distribution transformed scale. Parameters mapped back original scale evaluation. Currently supports \"log\", \"logit\", \"identity\". NULL, \"identity\" transformation used parameters. tune_control list pilot tuning controls (e.g., pilot_m, pilot_reps). See default_tune_control. verbose logical value indicating whether print information pilot_run tuning. Defaults FALSE. return_latent_state_est logical value indicating whether return latent state estimates time step. Defaults FALSE. seed optional integer set seed reproducibility. num_cores integer specifying number cores use parallel processing. Defaults 1. chain assigned core, number cores exceed number chains (num_chains). progress information given user limited using one core.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"list containing: theta_chain dataframe post burn-parameter samples. latent_state_chain return_latent_state_est   TRUE, list matrices containing latent state estimates   time step. diagnostics Diagnostics containing ESS Rhat   parameter (see ess rhat   documentation).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"PMMH algorithm essentially Metropolis Hastings algorithm instead using intractable marginal likelihood \\(p(y_{1:T}\\mid \\theta)\\) instead uses estimated likelihood using particle filter (see also particle_filter). Values proposed using multivariate normal distribution transformed space. proposal covariance number particles chosen based pilot run. minimum number particles chosen 50 maximum 1000.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"Andrieu et al. (2010). Particle Markov chain Monte Carlo methods. Journal Royal Statistical Society: Series B (Statistical Methodology), 72(3):269–342. doi: 10.1111/j.1467-9868.2009.00736.x","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/pmmh.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Particle Marginal Metropolis-Hastings (PMMH) for State-Space Models — pmmh","text":"","code":"init_fn <- function(num_particles) {   rnorm(num_particles, mean = 0, sd = 1) } transition_fn <- function(particles, phi, sigma_x) {   phi * particles + sin(particles) +     rnorm(length(particles), mean = 0, sd = sigma_x) } log_likelihood_fn <- function(y, particles, sigma_y) {   dnorm(y, mean = cos(particles), sd = sigma_y, log = TRUE) } log_prior_phi <- function(phi) {   dnorm(phi, mean = 0, sd = 1, log = TRUE) } log_prior_sigma_x <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_prior_sigma_y <- function(sigma) {   dexp(sigma, rate = 1, log = TRUE) } log_priors <- list(   phi = log_prior_phi,   sigma_x = log_prior_sigma_x,   sigma_y = log_prior_sigma_y ) # Generate data t_val <- 10 x <- numeric(t_val) y <- numeric(t_val) phi <- 0.8 sigma_x <- 1 sigma_y <- 0.5  init_state <- rnorm(1, mean = 0, sd = 1) x[1] <- phi * init_state + sin(init_state) + rnorm(1, mean = 0, sd = sigma_x) y[1] <- x[1] + rnorm(1, mean = 0, sd = sigma_y) for (t in 2:t_val) {   x[t] <- phi * x[t - 1] + sin(x[t - 1]) + rnorm(1, mean = 0, sd = sigma_x)   y[t] <- cos(x[t]) + rnorm(1, mean = 0, sd = sigma_y) } x <- c(init_state, x)  # Should use much higher MCMC iterations in practice (m) pmmh_result <- pmmh(   y = y,   m = 1000,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.8, sigma_x = 1, sigma_y = 0.5),     c(phi = 1, sigma_x = 0.5, sigma_y = 1)   ),   burn_in = 100,   num_chains = 2,   param_transform = list(     phi = \"identity\",     sigma_x = \"log\",     sigma_y = \"log\"   ),   tune_control = default_tune_control(pilot_m = 500, pilot_burn_in = 100) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median  2.5% 97.5% ESS  Rhat #>        phi 0.17 1.17   0.29 -2.27  2.23  26 1.084 #>    sigma_x 1.65 1.31   1.43  0.06  4.94  60 1.055 #>    sigma_y 0.78 0.30   0.73  0.37  1.50 149 1.017 #> Warning: Some ESS values are below 400, indicating poor mixing. Consider running the chains for more iterations. #> Warning:  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in. # Convergence warning is expected with such low MCMC iterations.  # Suppose we have data for t=1,2,3,5,6,7,8,9,10 (i.e., missing at t=4)  obs_times <- c(1, 2, 3, 5, 6, 7, 8, 9, 10) y <- y[obs_times]  # Specify observation times in the pmmh using obs_times pmmh_result <- pmmh(   y = y,   m = 1000,   init_fn = init_fn,   transition_fn = transition_fn,   log_likelihood_fn = log_likelihood_fn,   log_priors = log_priors,   pilot_init_params = list(     c(phi = 0.8, sigma_x = 1, sigma_y = 0.5),     c(phi = 1, sigma_x = 0.5, sigma_y = 1)   ),   burn_in = 100,   num_chains = 2,   obs_times = obs_times,   param_transform = list(     phi = \"identity\",     sigma_x = \"log\",     sigma_y = \"log\"   ),   tune_control = default_tune_control(pilot_m = 500, pilot_burn_in = 100) ) #> Running chain 1... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> Running chain 2... #> Running pilot chain for tuning... #> Using 50 particles for PMMH: #> Running Particle MCMC chain with tuned settings... #> PMMH Results Summary: #>  Parameter Mean   SD Median  2.5% 97.5% ESS  Rhat #>        phi 0.10 1.25   0.21 -2.16  2.16  48 1.054 #>    sigma_x 1.43 1.13   1.23  0.12  4.53 125 1.005 #>    sigma_y 0.79 0.36   0.72  0.32  1.66  53 1.054 #> Warning: Some ESS values are below 400, indicating poor mixing. Consider running the chains for more iterations. #> Warning:  #> Some Rhat values are above 1.01, indicating that the chains have not converged.  #> Consider running the chains for more iterations and/or increase burn_in."},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Print method for PMMH output — print.pmmh_output","title":"Print method for PMMH output — print.pmmh_output","text":"Displays concise summary parameter estimates PMMH output object, including means, standard deviations, medians, 95% credible intervals, effective sample sizes (ESS), Rhat. provides quick overview posterior distribution convergence diagnostics.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print method for PMMH output — print.pmmh_output","text":"","code":"# S3 method for class 'pmmh_output' print(x, ...)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print method for PMMH output — print.pmmh_output","text":"x object class `pmmh_output`. ... Additional arguments.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print method for PMMH output — print.pmmh_output","text":"object `x` invisibly.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/print.pmmh_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print method for PMMH output — print.pmmh_output","text":"","code":"# Create dummy chains for two parameters across two chains chain1 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 1) chain2 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 2) dummy_output <- list(   theta_chain = rbind(chain1, chain2),   diagnostics = list(     ess = c(param1 = 200, param2 = 190),     rhat = c(param1 = 1.01, param2 = 1.00)   ) ) class(dummy_output) <- \"pmmh_output\" print(dummy_output) #> PMMH Results Summary: #>  Parameter  Mean   SD Median  2.5% 97.5% ESS Rhat #>     param1  0.10 1.04   0.03 -1.73  1.99 200 1.01 #>     param2 -0.01 0.96  -0.04 -1.70  1.97 190 1.00"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute split Rhat statistic — rhat","title":"Compute split Rhat statistic — rhat","text":"Compute split Rhat statistic","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute split Rhat statistic — rhat","text":"","code":"rhat(chains)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute split Rhat statistic — rhat","text":"chains matrix (iterations x chains) data.frame 'chain' column parameter columns.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute split Rhat statistic — rhat","text":"Rhat value (matrix input) named vector Rhat values.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compute split Rhat statistic — rhat","text":"Uses formula split-Rhat proposed Gelman et al. (2013).","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Compute split Rhat statistic — rhat","text":"Gelman et al. (2013). Bayesian Data Analysis, 3rd Edition.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/rhat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compute split Rhat statistic — rhat","text":"","code":"# Example with matrix chains <- matrix(rnorm(3000), nrow = 1000, ncol = 3) rhat(chains) #> [1] 1.001842 #' # Example with data frame chains_df <- data.frame(   chain = rep(1:3, each = 1000),   param1 = rnorm(3000),   param2 = rnorm(3000) ) rhat(chains_df) #>   param1   param2  #> 1.001030 1.001103"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Summary method for PMMH output — summary.pmmh_output","title":"Summary method for PMMH output — summary.pmmh_output","text":"function returns summary statistics PMMH output objects, including means, standard deviations, medians, credible intervals, diagnostics.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summary method for PMMH output — summary.pmmh_output","text":"","code":"# S3 method for class 'pmmh_output' summary(object, ...)"},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summary method for PMMH output — summary.pmmh_output","text":"object object class `pmmh_output`. ... Additional arguments.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summary method for PMMH output — summary.pmmh_output","text":"data frame containing summary statistics parameter.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/reference/summary.pmmh_output.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summary method for PMMH output — summary.pmmh_output","text":"","code":"# Create dummy chains for two parameters across two chains chain1 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 1) chain2 <- data.frame(param1 = rnorm(100), param2 = rnorm(100), chain = 2) dummy_output <- list(   theta_chain = rbind(chain1, chain2),   diagnostics = list(     ess = c(param1 = 200, param2 = 190),     rhat = c(param1 = 1.01, param2 = 1.00)   ) ) class(dummy_output) <- \"pmmh_output\" summary(dummy_output) #>               mean        sd      median      2.5%    97.5% ESS Rhat #> param1  0.03028700 1.1791722 -0.08151270 -2.406859 2.344359 200 1.01 #> param2 -0.05183869 0.9637325 -0.03151819 -1.980977 1.798555 190 1.00"},{"path":"https://bjarkehautop.github.io/bayesSSM/news/index.html","id":"bayesssm-development-version","dir":"Changelog","previous_headings":"","what":"bayesSSM (development version)","title":"bayesSSM (development version)","text":"Improved reproducibility pmmh: Setting seed now ensures consistent results regardless number cores used. Improvement performance pmmh slightly.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/news/index.html","id":"bayesssm-050","dir":"Changelog","previous_headings":"","what":"bayesSSM 0.5.0","title":"bayesSSM 0.5.0","text":"CRAN release: 2025-05-21 particles argument init_fn, passed particle_filter pmmh, deprecated. Please use num_particles instead. warning issued particles used. Added support time dependency functions. can now use t transition_fn likelihood_fn passing particle_filter pmmh. allows time-varying transition likelihood functions. Fixed bug particle_filter likelihood calculation causing shifted constant. Improved robustness pmmh encountering low log-likelihood values. Added scaling proposal covariance using \"logit\" pmmh. Improved documentation: updated package description, clarified text README vignette, added unit tests.","code":""},{"path":"https://bjarkehautop.github.io/bayesSSM/news/index.html","id":"bayesssm-047","dir":"Changelog","previous_headings":"","what":"bayesSSM 0.4.7","title":"bayesSSM 0.4.7","text":"CRAN release: 2025-04-23 Initial CRAN submission.","code":""}]
